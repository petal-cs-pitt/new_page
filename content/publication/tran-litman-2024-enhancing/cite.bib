@inproceedings{tran-litman-2024-enhancing,
 abstract = {Knowledge retrieval is one of the major challenges in building a knowledge-grounded dialogue system. A common method is to use a neural retriever with a distributed approximate nearest-neighbor database to quickly find the relevant knowledge sentences. In this work, we propose an approach that utilizes topic modeling on the knowledge base to further improve retrieval accuracy and as a result, improve response generation. Additionally, we experiment with a large language model (LLM), ChatGPT, to take advantage of the improved retrieval performance to further improve the generation results. Experimental results on two datasets show that our approach can increase retrieval and generation performance. The results also indicate that ChatGPT is a better response generator for knowledge-grounded dialogue when relevant knowledge is provided.},
 address = {Torino, Italia},
 author = {Tran, Nhat  and
Litman, Diane},
 booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
 editor = {Calzolari, Nicoletta  and
Kan, Min-Yen  and
Hoste, Veronique  and
Lenci, Alessandro  and
Sakti, Sakriani  and
Xue, Nianwen},
 month = {May},
 pages = {5986--5995},
 publisher = {ELRA and ICCL},
 title = {Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue},
 url = {https://aclanthology.org/2024.lrec-main.530},
 year = {2024}
}

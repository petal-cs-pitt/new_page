---
title: Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue
authors:
- Nhat Tran
- Diane Litman
date: '2024-05-01'
publishDate: '2024-09-06T20:59:49.374573Z'
publication_types:
- '1'
publication: '*Proceedings of the 2024 Joint International Conference on Computational
  Linguistics, Language Resources and Evaluation (LREC-COLING 2024)*'
abstract: Knowledge retrieval is one of the major challenges in building a knowledge-grounded
  dialogue system. A common method is to use a neural retriever with a distributed
  approximate nearest-neighbor database to quickly find the relevant knowledge sentences.
  In this work, we propose an approach that utilizes topic modeling on the knowledge
  base to further improve retrieval accuracy and as a result, improve response generation.
  Additionally, we experiment with a large language model (LLM), ChatGPT, to take
  advantage of the improved retrieval performance to further improve the generation
  results. Experimental results on two datasets show that our approach can increase
  retrieval and generation performance. The results also indicate that ChatGPT is
  a better response generator for knowledge-grounded dialogue when relevant knowledge
  is provided.

---
